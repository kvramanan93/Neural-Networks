{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-09T10:42:53.426977Z",
     "start_time": "2024-08-09T10:42:53.424270Z"
    }
   },
   "source": [
    "import random\n",
    "import sys\n",
    "sys.path.append('D:\\Downloads\\MakeMore\\pythonProject1\\.venv\\Micrograd')\n",
    "from engine import Value"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T11:27:07.551166Z",
     "start_time": "2024-08-09T11:27:07.539034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Module:\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in parameters():\n",
    "            p.grad = 0\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Neuron(Module):\n",
    "    def __init__(self,nin,nonlin=True):\n",
    "        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "        self.b = Value(0)\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        act = sum((wi*xi) for wi,xi in zip(self.w,x))+self.b \n",
    "        return act.reLU() if self.nonlin else act\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
    "        \n",
    "    \n",
    "class Layers(Module):\n",
    "    def __init__(self,nin,nouts,**kwargs):\n",
    "        self.neurons = [Neuron(nin,**kwargs) for _ in range(nout)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out[0] if len(out) == 1 else out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self,nin,nouts):\n",
    "        sz = [nin]+nouts\n",
    "        self.layers = [Layers(sz[i],sz[i+1],nonlin=i!=len(nouts)) for i in range(len(nouts))]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MLP of [{', '.join(str(layer) for layer in self.layers)}]\""
   ],
   "id": "7a5e609dc56b39b",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
